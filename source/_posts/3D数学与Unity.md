---
layout: title
title: 3D数学与Unity
date: 2019-04-06 17:16:21
categories: Unity
tags: Unity 3D实战核心技术详解
---
用Unity引擎开发游戏就是在引擎的上层再封装一层游戏架构，在游戏开发的逻辑中需要根据需求重新封装一些数学算法以便于逻辑调用。

<!--more-->

Unity底层全部使用C/C++与OpenGL ES 3D渲染引擎交互，C#端封装了UnityEditor.DLL和UnityEngine.DLL，通过与Unity内部C/C++代码交互从而与底层代码相互调用。开发者只需要编写C#代码访问Unity提供的UnityEditor.DLL及其提供的API接口即可从容地开发3D游戏。

Unity的效率并不高。在UI层面，界面元素稍微多一点打开界面的时候就会出现卡顿。在3D层面，同屏人数多一点或者Shader复杂一些，帧率马上就掉下去了。

关于热更新，更多是用来修正游戏Bug的。如果没有热更新，修改一个Bug后需要重新提交App Store评审，这样来来回回可能要耽误好几天时间，不是很合理。由于苹果禁止了JIT，Unity官方没有提供热更新的方案，因此都采用Lua进行热更新的开发。虽然Lua的解释器可以用C++代码解释，但是在处理Lua与C#之间穿透的时候依然会很慢，程序设计不合理就会产生性能问题。

所以Unity最大的痛点就是性能问题，它上手确非常地灵活，但是太灵活就可能会被滥用。

# Unity坐标系

3D坐标系表示的是三维空间，3D坐标系存在三个坐标轴，分别为x轴、y轴、z轴，如图1-1所示。

{% asset_img 1.png %}

3D坐标系分为左手坐标系和右手坐标系。Unity使用的是左手坐标系。

Unity引擎的左手坐标系也被称为世界坐标系，做游戏开发时需要美工制作美术模型，运用MAX工具把建好的模型放到游戏场景中。在默认情况下，局部坐标和世界坐标系的原点是重合的，不能把所有的模型都叠加在世界坐标系的原点上，因此需要移动模型。模型移动时就会发生模型的局部坐标到世界坐标的转换，这个移动过程就是把模型的局部坐标转化成世界坐标。只是这个转化过程是在引擎编辑器内部实现的，实际上它就是将模型的各个点与世界矩阵相乘得到的。Unity编辑器中的物体都在世界坐标系里面，比如我们通常使用的函数transform.position，它就是获取到当前物体的世界坐标位置，用户无须自己去计算，因为引擎内部已经计算好了。明白了原理后，再使用编辑器解决问题更有助于理解，做到知其然且知其所以然。如果要获取物体自身的坐标，也就是局部坐标，可以使用函数transform.localPosition获取当前模型的局部坐标。

用Unity引擎开发移动端手游会经常用到屏幕坐标系，屏幕坐标系就是通常使用的电脑屏幕，它是以像素为单位的，屏幕左下角为（0，0）点，右上角为（Screen.Width，Screen.Height）点，Z的位置是根据相机的Z缓存值确定的。通常使用鼠标在屏幕上单击物体，它就是屏幕坐标。通过函数Input.mousePosition可以获得鼠标位置的坐标。我们使用的虚拟摇杆可以在屏幕上滑动，它也是屏幕坐标，可以通过函数Input.GetTouch（0）.position获取到手指触摸屏幕坐标。在游戏开发中，比如单击场景中的3D物体就需要从屏幕上发射一条射线与物体的包围盒相交，用于判断是否选中物体，对于UI的操作也都是基于屏幕坐标系的。
通过相机才能看到虚拟世界的物体。相机有自己的视口坐标，物体要转换到视口坐标才能被看到。相机的视口左下角为（0，0）点，右上角为（1，1）点，Z的位置是以相机的世界单位来衡量的。（0，0）点和（1，1）点是通过公式进行缩放计算的，这里面存在一个变换，读者了解就可以了。这也是为什么视口的大小通常都是（0，0）和（1，1），效果如图1-2所示，图的中心点是摄像机。